{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\putri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\putri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\putri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\putri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (50, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   No              No. Putusan Lembaga Peradilan  \\\n0   1  462/Pid.Sus/2022/PN.Sda       PN Sidoarjo   \n1   2  456/Pid.Sus/2022/PN.Sda       PN Sidoarjo   \n2   3  487/Pid.Sus/2022/PN Sda       PN Sidoarjo   \n3   4  471/Pid.Sus/2022/PN Sda       PN Sidoarjo   \n4   5  512/Pid.Sus/2022/PN Sda       PN Sidoarjo   \n\n                                        Barang Bukti  \\\n0  1 (satu) buah pipet kaca bekas pakai sabu terd...   \n1  16 (enam belas) bungkus plastic klip yang dida...   \n2  Sebuah bungkus teh celup yang di dalamnya beri...   \n3  1 (satu) pocket plastik klip berisi Narkotika ...   \n4  1 (satu) bungkus plastik klip ukuran kecil yan...   \n\n                                        Amar_Putusan  \n0  Menyatakan Terdakwa Kartini alias Mama Mila bi...  \n1  Menyatakan terdakwa Duri Setiawan bin Subiyat ...  \n2  Menyatakan Para Terdakwa I. Rihan Iswahyudi bi...  \n3  Menyatakan terdakwa Muhammad Darmadi Pranggono...  \n4  Menyatakan Terdakwa ALI HAMZA Bin ZULKIFLI RIT...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>No</th>\n      <th>No. Putusan</th>\n      <th>Lembaga Peradilan</th>\n      <th>Barang Bukti</th>\n      <th>Amar_Putusan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>462/Pid.Sus/2022/PN.Sda</td>\n      <td>PN Sidoarjo</td>\n      <td>1 (satu) buah pipet kaca bekas pakai sabu terd...</td>\n      <td>Menyatakan Terdakwa Kartini alias Mama Mila bi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>456/Pid.Sus/2022/PN.Sda</td>\n      <td>PN Sidoarjo</td>\n      <td>16 (enam belas) bungkus plastic klip yang dida...</td>\n      <td>Menyatakan terdakwa Duri Setiawan bin Subiyat ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>487/Pid.Sus/2022/PN Sda</td>\n      <td>PN Sidoarjo</td>\n      <td>Sebuah bungkus teh celup yang di dalamnya beri...</td>\n      <td>Menyatakan Para Terdakwa I. Rihan Iswahyudi bi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>471/Pid.Sus/2022/PN Sda</td>\n      <td>PN Sidoarjo</td>\n      <td>1 (satu) pocket plastik klip berisi Narkotika ...</td>\n      <td>Menyatakan terdakwa Muhammad Darmadi Pranggono...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>512/Pid.Sus/2022/PN Sda</td>\n      <td>PN Sidoarjo</td>\n      <td>1 (satu) bungkus plastik klip ukuran kecil yan...</td>\n      <td>Menyatakan Terdakwa ALI HAMZA Bin ZULKIFLI RIT...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_excel(\"C:/Users/putri/DataspellProjects/dsProject/Overview.xlsx\")\n",
    "print('data shape: ', dataset.shape)\n",
    "dataset.head() # prints the first 5 rows of the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "outputs": [
    {
     "data": {
      "text/plain": "No                   0\nNo. Putusan          0\nLembaga Peradilan    0\nBarang Bukti         0\nAmar_Putusan         0\ndtype: int64"
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "outputs": [],
   "source": [
    "for i,txt in enumerate(dataset['Amar_Putusan']):\n",
    "    subject = re.findall('Subject:(.*\\n)',txt)\n",
    "    if (len(subject) !=0):\n",
    "        dataset.loc[i,'Subject'] =str(i)+' '+subject[0]\n",
    "    else:\n",
    "        dataset.loc[i,'Subject'] ='NA'\n",
    "df_news = dataset[['Subject','Amar_Putusan']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     NA\n",
      "1     NA\n",
      "2     NA\n",
      "3     NA\n",
      "4     NA\n",
      "5     NA\n",
      "6     NA\n",
      "7     NA\n",
      "8     NA\n",
      "9     NA\n",
      "10    NA\n",
      "11    NA\n",
      "12    NA\n",
      "13    NA\n",
      "14    NA\n",
      "15    NA\n",
      "16    NA\n",
      "17    NA\n",
      "18    NA\n",
      "19    NA\n",
      "20    NA\n",
      "21    NA\n",
      "22    NA\n",
      "23    NA\n",
      "24    NA\n",
      "25    NA\n",
      "26    NA\n",
      "27    NA\n",
      "28    NA\n",
      "29    NA\n",
      "30    NA\n",
      "31    NA\n",
      "32    NA\n",
      "33    NA\n",
      "34    NA\n",
      "35    NA\n",
      "36    NA\n",
      "37    NA\n",
      "38    NA\n",
      "39    NA\n",
      "40    NA\n",
      "41    NA\n",
      "42    NA\n",
      "43    NA\n",
      "44    NA\n",
      "45    NA\n",
      "46    NA\n",
      "47    NA\n",
      "48    NA\n",
      "49    NA\n",
      "Name: Subject, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_news['Subject'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "outputs": [],
   "source": [
    "df_data =dataset[['Subject','Amar_Putusan']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "outputs": [],
   "source": [
    "# Change all the text to lower case\n",
    "df_data['Amar_Putusan']=[entry.lower() for entry in df_data['Amar_Putusan']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [],
   "source": [
    "## data Cleaning for content data of news\n",
    "df_data.Amar_Putusan =df_data.Amar_Putusan.replace(to_replace='from:(.*\\n)',value='',regex=True)\n",
    "df_data.Amar_Putusan =df_data.Amar_Putusan.replace(to_replace='lines:(.*\\n)',value='',regex=True)\n",
    "df_data.Amar_Putusan =df_data.Amar_Putusan.replace(to_replace='[!\"#$%&\\'()*+,/:;<=>?@[\\\\]^_`{|}~]',value=' ',regex=True) #remove punctuation except\n",
    "df_data.Amar_Putusan =df_data.Amar_Putusan.replace(to_replace='-',value=' ',regex=True)\n",
    "df_data.Amar_Putusan =df_data.Amar_Putusan.replace(to_replace='\\s+',value=' ',regex=True)    #remove new line\n",
    "df_data.Amar_Putusan =df_data.Amar_Putusan.replace(to_replace='  ',value='',regex=True)                #remove double white space\n",
    "df_data.Amar_Putusan =df_data.Amar_Putusan.apply(lambda x:x.strip())  # Ltrim and Rtrim of whitespace"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "outputs": [],
   "source": [
    "## data cleaning for subject data\n",
    "df_data.Subject =df_data.Subject.replace(to_replace='Re:',value='',regex=True)\n",
    "df_data.Subject =df_data.Subject.replace(to_replace='[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~]',value=' ',regex=True)\n",
    "df_data.Subject =df_data.Subject.replace(to_replace='\\s+',value=' ',regex=True)    #remove new line\n",
    "df_data.Subject =df_data.Subject.replace(to_replace='  ',value='',regex=True)    #remove double white space\n",
    "df_data.Subject =df_data.Subject.apply(lambda x:x.strip())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "outputs": [],
   "source": [
    "## ## Checking  and drop empty data\n",
    "for i,sen in enumerate(df_data.Amar_Putusan):\n",
    "    if len(sen.strip()) ==0:\n",
    "        print(str(i))\n",
    "        #file_data.text[i] = np.nan\n",
    "        df_data=df_data.drop(str(i),axis=0).reset_index().drop('index',axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "outputs": [],
   "source": [
    "# okenization : In this each entry in the file_data will be broken into set of words\n",
    "df_data['Word tokenize']= [word_tokenize(entry) for entry in df_data.Amar_Putusan]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "outputs": [],
   "source": [
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "def wordLemmatizer(data):\n",
    "    tag_map = defaultdict(lambda : wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "    file_clean_k =pd.DataFrame()\n",
    "    for index,entry in enumerate(data):\n",
    "\n",
    "        # Declaring Empty List to store the words that follow the rules for this step\n",
    "        Final_words = []\n",
    "        # Initializing WordNetLemmatizer()\n",
    "        word_Lemmatized = WordNetLemmatizer()\n",
    "        stop_factory = StopWordRemoverFactory()\n",
    "        # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "        for word, tag in pos_tag(entry):\n",
    "            # Below condition is to check for Stop words and consider only alphabets\n",
    "            if len(word)>1 and word not in stop_factory.get_stop_words() and word.isalpha():\n",
    "                word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "                Final_words.append(word_Final)\n",
    "                # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "                file_clean_k.loc[index,'Keyword_final'] = str(Final_words)\n",
    "                file_clean_k.loc[index,'Keyword_final'] = str(Final_words)\n",
    "                #file_clean_k=file_clean_k.replace(to_replace =\"\\[.\", value = '', regex = True)\n",
    "                #file_clean_k=file_clean_k.replace(to_replace =\"'\", value = '', regex = True)\n",
    "                #file_clean_k=file_clean_k.replace(to_replace =\" \", value = '', regex = True)\n",
    "                #file_clean_k=file_clean_k.replace(to_replace ='\\]', value = '', regex = True)\n",
    "    return file_clean_k"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        Keyword_final\n0   ['menyatakan', 'terdakwa', 'kartini', 'alias',...\n1   ['menyatakan', 'terdakwa', 'duri', 'setiawan',...\n2   ['menyatakan', 'terdakwa', 'rihan', 'iswahyudi...\n3   ['menyatakan', 'terdakwa', 'muhammad', 'darmad...\n4   ['menyatakan', 'terdakwa', 'ali', 'hamza', 'bi...\n5   ['menyatakan', 'terdakwa', 'najih', 'shihabfud...\n6   ['menyatakan', 'terdakwa', 'yusron', 'arizona'...\n7   ['menyatakan', 'terdakwa', 'launa', 'wahyudi',...\n8   ['menyatakan', 'terdakwa', 'suryono', 'bin', '...\n9   ['menyatakan', 'terdakwa', 'mohammad', 'nagara...\n10  ['menyatakan', 'terdakwa', 'junaidi', 'al', 'j...\n11  ['menyatakan', 'terdakwa', 'agus', 'budi', 'se...\n12  ['menyatakan', 'terdakwa', 'mukayit', 'bin', '...\n13  ['menyatakan', 'terdakwa', 'billy', 'dimas', '...\n14  ['menyatakan', 'terdakwa', 'febri', 'antoko', ...\n15  ['menyatakan', 'terdakwa', 'mochamad', 'tiok',...\n16  ['menyatakan', 'terdakwa', 'randa', 'prayoga',...\n17  ['menyatakan', 'terdakwa', 'damar', 'mada', 'b...\n18  ['menyatakan', 'terdakwa', 'irwan', 'chabib', ...\n19  ['menyatakan', 'terdakwa', 'rahmat', 'surya', ...\n20  ['menyatakan', 'terdakwa', 'muhammad', 'ramada...\n21  ['menyatakan', 'terdakwa', 'muhammad', 'zainud...\n22  ['menyatakan', 'terdakwa', 'ach', 'zainuri', '...\n23  ['menyatakan', 'terdakwa', 'khusen', 'bin', 's...\n24  ['menyatakan', 'terdakwa', 'achmad', 'maliki',...\n25  ['menyatakan', 'terdakwa', 'achmad', 'choirul'...\n26  ['menyatakan', 'terdakwa', 'adi', 'setiawan', ...\n27  ['menyatakan', 'terdakwa', 'fery', 'wisnu', 's...\n28  ['menyatakan', 'terdakwa', 'idris', 'chulaifi'...\n29  ['menyatakan', 'terdakwa', 'prangga', 'agustia...\n30  ['menyatakan', 'terdakwa', 'darwis', 'bin', 'm...\n31  ['menyatakan', 'terdakwa', 'angga', 'dwi', 'pr...\n32  ['menyatakan', 'terdakwa', 'boy', 'anggriawan'...\n33  ['menyatakan', 'terdakwa', 'moh', 'rolis', 'bi...\n34  ['menyatakan', 'terdakwa', 'yudha', 'kurniawan...\n35  ['menyatakan', 'terdakwa', 'okky', 'agung', 'b...\n36  ['menyatakan', 'terdakwa', 'selamet', 'utomo',...\n37  ['menyatakan', 'terdakwa', 'alvialy', 'rifdaya...\n38  ['menyatakan', 'terdakwa', 'terdakwa', 'andik'...\n39  ['menyatakan', 'terdakwa', 'arman', 'maulana',...\n40  ['menyatakan', 'terdakwa', 'antok', 'bin', 'sl...\n41  ['menyatakan', 'terdakwa', 'novan', 'gama', 'a...\n42  ['menyatakan', 'terdakwa', 'zuneehru', 'yuda',...\n43  ['menyatakan', 'terdakwa', 'mochamad', 'ma', '...\n44  ['menyatakan', 'terdakwa', 'andri', 'lesmana',...\n45  ['menyatakan', 'terdakwa', 'mochamad', 'choiri...\n46  ['menyatakan', 'terdakwa', 'wahid', 'wahyu', '...\n47  ['menyatakan', 'terdakwa', 'widi', 'joko', 'pr...\n48  ['menyatakan', 'terdakwa', 'aprianto', 'hermaw...\n49  ['menyatakan', 'terdakwa', 'prasetyo', 'b', 'b...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Keyword_final</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>['menyatakan', 'terdakwa', 'kartini', 'alias',...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>['menyatakan', 'terdakwa', 'duri', 'setiawan',...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>['menyatakan', 'terdakwa', 'rihan', 'iswahyudi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>['menyatakan', 'terdakwa', 'muhammad', 'darmad...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>['menyatakan', 'terdakwa', 'ali', 'hamza', 'bi...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>['menyatakan', 'terdakwa', 'najih', 'shihabfud...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>['menyatakan', 'terdakwa', 'yusron', 'arizona'...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>['menyatakan', 'terdakwa', 'launa', 'wahyudi',...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>['menyatakan', 'terdakwa', 'suryono', 'bin', '...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>['menyatakan', 'terdakwa', 'mohammad', 'nagara...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>['menyatakan', 'terdakwa', 'junaidi', 'al', 'j...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>['menyatakan', 'terdakwa', 'agus', 'budi', 'se...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>['menyatakan', 'terdakwa', 'mukayit', 'bin', '...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>['menyatakan', 'terdakwa', 'billy', 'dimas', '...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>['menyatakan', 'terdakwa', 'febri', 'antoko', ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>['menyatakan', 'terdakwa', 'mochamad', 'tiok',...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>['menyatakan', 'terdakwa', 'randa', 'prayoga',...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>['menyatakan', 'terdakwa', 'damar', 'mada', 'b...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>['menyatakan', 'terdakwa', 'irwan', 'chabib', ...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>['menyatakan', 'terdakwa', 'rahmat', 'surya', ...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>['menyatakan', 'terdakwa', 'muhammad', 'ramada...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>['menyatakan', 'terdakwa', 'muhammad', 'zainud...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>['menyatakan', 'terdakwa', 'ach', 'zainuri', '...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>['menyatakan', 'terdakwa', 'khusen', 'bin', 's...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>['menyatakan', 'terdakwa', 'achmad', 'maliki',...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>['menyatakan', 'terdakwa', 'achmad', 'choirul'...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>['menyatakan', 'terdakwa', 'adi', 'setiawan', ...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>['menyatakan', 'terdakwa', 'fery', 'wisnu', 's...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>['menyatakan', 'terdakwa', 'idris', 'chulaifi'...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>['menyatakan', 'terdakwa', 'prangga', 'agustia...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>['menyatakan', 'terdakwa', 'darwis', 'bin', 'm...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>['menyatakan', 'terdakwa', 'angga', 'dwi', 'pr...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>['menyatakan', 'terdakwa', 'boy', 'anggriawan'...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>['menyatakan', 'terdakwa', 'moh', 'rolis', 'bi...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>['menyatakan', 'terdakwa', 'yudha', 'kurniawan...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>['menyatakan', 'terdakwa', 'okky', 'agung', 'b...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>['menyatakan', 'terdakwa', 'selamet', 'utomo',...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>['menyatakan', 'terdakwa', 'alvialy', 'rifdaya...</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>['menyatakan', 'terdakwa', 'terdakwa', 'andik'...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>['menyatakan', 'terdakwa', 'arman', 'maulana',...</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>['menyatakan', 'terdakwa', 'antok', 'bin', 'sl...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>['menyatakan', 'terdakwa', 'novan', 'gama', 'a...</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>['menyatakan', 'terdakwa', 'zuneehru', 'yuda',...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>['menyatakan', 'terdakwa', 'mochamad', 'ma', '...</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>['menyatakan', 'terdakwa', 'andri', 'lesmana',...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>['menyatakan', 'terdakwa', 'mochamad', 'choiri...</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>['menyatakan', 'terdakwa', 'wahid', 'wahyu', '...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>['menyatakan', 'terdakwa', 'widi', 'joko', 'pr...</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>['menyatakan', 'terdakwa', 'aprianto', 'hermaw...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>['menyatakan', 'terdakwa', 'prasetyo', 'b', 'b...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This Function took around 13 hours for word Lemmatized and remove the Stop words & single character of word of each 11314 rows.\n",
    "df_clean = wordLemmatizer(df_data['Word tokenize'][0:50])\n",
    "df_clean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "outputs": [],
   "source": [
    "df_clean=df_clean.replace(to_replace =\"\\[.\", value = '', regex = True)\n",
    "df_clean=df_clean.replace(to_replace =\"'\", value = '', regex = True)\n",
    "df_clean=df_clean.replace(to_replace =\" \", value = '', regex = True)\n",
    "df_clean=df_clean.replace(to_replace ='\\]', value = '', regex = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [],
   "source": [
    "## Insert New column in df_news to stored the Clean Keyword\n",
    "df_data.insert(loc=3, column='Clean_Keyword', value=df_clean['Keyword_final'].tolist())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [],
   "source": [
    "## Already Word lemmatize clean keywords the below path:-\n",
    "\n",
    "#df_news[['Subject','Clean_Keyword']].to_json(\"WordLemmatize20NewsGroup.json\")\n",
    "df =pd.read_json('C:/Users/putri/DataspellProjects/dsProject/DatasetInformasi.json')\n",
    "df_data['Clean_Keyword'] =df['Clean_Keyword']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [
    {
     "data": {
      "text/plain": "   Subject                                       Amar_Putusan\n0       NA  menyatakan terdakwa kartini alias mama mila bi...\n1       NA  menyatakan terdakwa duri setiawan bin subiyat ...\n2       NA  menyatakan para terdakwa i. rihan iswahyudi bi...\n3       NA  menyatakan terdakwa muhammad darmadi pranggono...\n4       NA  menyatakan terdakwa ali hamza bin zulkifli rit...\n5       NA  menyatakan terdakwa m. najih shihabfudin alias...\n6       NA  menyatakan terdakwa yusron arizona alias aris ...\n7       NA  menyatakan terdakwa launa wahyudi bin achamad ...\n8       NA  menyatakan terdakwa suryono bin suparman telah...\n9       NA  menyatakan terdakwa mohammad nagarawan dwi pra...\n10      NA  menyatakan terdakwa junaidi als jun bin kholil...\n11      NA  menyatakan terdakwa agus budi setiawan alias t...\n12      NA  menyatakan terdakwa mukayit bin suandi tersebu...\n13      NA  menyatakan terdakwa billy dimas danu barata bi...\n14      NA  menyatakan bahwa terdakwa febri antoko sudarso...\n15      NA  menyatakan terdakwa mochamad tiok kariyadi bin...\n16      NA  menyatakan terdakwa randa prayoga bin suprapto...\n17      NA  menyatakan terdakwa damar mada bhaskara bin an...\n18      NA  menyatakan terdakwa irwan chabib als habi bin ...\n19      NA  menyatakan terdakwa rahmat surya agung bin sai...\n20      NA  menyatakan terdakwa muhammad ramadany fasdama ...\n21      NA  menyatakan terdakwa muhammad zainudin bin abdu...\n22      NA  menyatakan terdakwa ach. zainuri alias ogut bi...\n23      NA  menyatakan terdakwa i. khusen bin satimun alm ...\n24      NA  menyatakan terdakwa achmad maliki bin selamet ...\n25      NA  menyatakan terdakwa achmad choirul bin subari ...\n26      NA  menyatakan terdakwa adi setiawan bin nawariyan...\n27      NA  menyatakan terdakwa fery wisnu saputra alias p...\n28      NA  menyatakan terdakwa idris chulaifi bin matnaza...\n29      NA  menyatakan terdakwa prangga agustiansyah alias...\n30      NA  menyatakan terdakwa m. darwis bin mat bakri te...\n31      NA  menyatakan terdakwa angga dwi prasetyo bin her...\n32      NA  menyatakan terdakwa boy anggriawan bin yunefi ...\n33      NA  menyatakan terdakwa moh. rolis bin abdul rohma...\n34      NA  menyatakan terdakwa yudha kurniawan arvianto b...\n35      NA  menyatakan terdakwa okky agung p bin eko siswa...\n36      NA  menyatakan terdakwa selamet utomo bin ponidi t...\n37      NA  menyatakan terdakwa alvialy rifdayanto sebba b...\n38      NA  menyatakan terdakwa terdakwa andik kuswanto al...\n39      NA  menyatakan terdakwa arman maulana alias arman ...\n40      NA  menyatakan terdakwa antok bin slamet tersebut ...\n41      NA  menyatakan terdakwa novan gama andhy artha bin...\n42      NA  menyatakan terdakwa i zuneehru yuda prayoga al...\n43      NA  menyatakan terdakwa mochamad ma’ruf bin muhamm...\n44      NA  menyatakan terdakwa i. andri lesmana bin bamba...\n45      NA  menyatakan terdakwa mochamad choiril als. gino...\n46      NA  menyatakan terdakwa wahid wahyu susanto bin wa...\n47      NA  menyatakan terdakwa widi joko prawismo bin teg...\n48      NA  menyatakan terdakwa aprianto hermawan alias pa...\n49      NA  menyatakan terdakwa prasetyo bs bin bambang su...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Subject</th>\n      <th>Amar_Putusan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa kartini alias mama mila bi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa duri setiawan bin subiyat ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NA</td>\n      <td>menyatakan para terdakwa i. rihan iswahyudi bi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa muhammad darmadi pranggono...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa ali hamza bin zulkifli rit...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa m. najih shihabfudin alias...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa yusron arizona alias aris ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa launa wahyudi bin achamad ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa suryono bin suparman telah...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa mohammad nagarawan dwi pra...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa junaidi als jun bin kholil...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa agus budi setiawan alias t...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa mukayit bin suandi tersebu...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa billy dimas danu barata bi...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>NA</td>\n      <td>menyatakan bahwa terdakwa febri antoko sudarso...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa mochamad tiok kariyadi bin...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa randa prayoga bin suprapto...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa damar mada bhaskara bin an...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa irwan chabib als habi bin ...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa rahmat surya agung bin sai...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa muhammad ramadany fasdama ...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa muhammad zainudin bin abdu...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa ach. zainuri alias ogut bi...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa i. khusen bin satimun alm ...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa achmad maliki bin selamet ...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa achmad choirul bin subari ...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa adi setiawan bin nawariyan...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa fery wisnu saputra alias p...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa idris chulaifi bin matnaza...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa prangga agustiansyah alias...</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa m. darwis bin mat bakri te...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa angga dwi prasetyo bin her...</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa boy anggriawan bin yunefi ...</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa moh. rolis bin abdul rohma...</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa yudha kurniawan arvianto b...</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa okky agung p bin eko siswa...</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa selamet utomo bin ponidi t...</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa alvialy rifdayanto sebba b...</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa terdakwa andik kuswanto al...</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa arman maulana alias arman ...</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa antok bin slamet tersebut ...</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa novan gama andhy artha bin...</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa i zuneehru yuda prayoga al...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa mochamad ma’ruf bin muhamm...</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa i. andri lesmana bin bamba...</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa mochamad choiril als. gino...</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa wahid wahyu susanto bin wa...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa widi joko prawismo bin teg...</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa aprianto hermawan alias pa...</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>NA</td>\n      <td>menyatakan terdakwa prasetyo bs bin bambang su...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_save= df_data\n",
    "df_news_save = df_news_save.drop(['Word tokenize','Clean_Keyword'],axis=1)\n",
    "df_news_save"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 4 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 2 0 0 0 0 0 2 0 0 1 0 1 0 0 0 0 2 0 0 0 1 0 1 0 1 2 0 0\n",
      "  1 0 0 0 1 1 0 0 1 0 0 0 5 0 1 2 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 3 0 0 3 0 0 2 0 0 0 0 0 2 3 0 0 3 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
      "  0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 1 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0\n",
      "  0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1\n",
      "  0 0 0 1 0 1 0 0 0 0 0 0 2 0 0 0 1 1 0 0 2 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1\n",
      "  0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 1 0 0 0 0 1 0 0 0 0 2 0 0 0 1 1 0 0 0 5 0 2 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 2 0 0 0 0 0 0 0 2 0 3 1 0 0 0 0 1 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 1 0\n",
      "  0 1 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 1 2 1 0 0 0 0 0 0\n",
      "  1 1 5 1 0 1 0 1 1 1 1 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "train_vectors = count_vectorizer.fit_transform(df_data['Amar_Putusan'])\n",
    "print(train_vectors[0].todense())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "## Create Vocabulary\n",
    "vocabulary = set()\n",
    "\n",
    "for doc in df_data.Clean_Keyword:\n",
    "    vocabulary.update(doc.split(','))\n",
    "\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "# Intializating the tfIdf model\n",
    "tfidf = TfidfVectorizer(vocabulary=vocabulary,dtype=np.float32)\n",
    "\n",
    "# Fit the TfIdf model\n",
    "tfidf.fit(df_data.Clean_Keyword)\n",
    "\n",
    "# Transform the TfIdf model\n",
    "tfidf_tran=tfidf.transform(df_data.Clean_Keyword)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "outputs": [
    {
     "data": {
      "text/plain": "['diatur', 'selamet', 'mama', 'dedik']"
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[0:4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "outputs": [],
   "source": [
    "with open('C:/Users/putri/DataspellProjects/dsProject/tfid.pkl','wb') as handle:\n",
    "    pickle.dump(tfidf_tran, handle)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "outputs": [],
   "source": [
    "### load model\n",
    "t = pickle.load(open('C:/Users/putri/DataspellProjects/dsProject/tfid.pkl','rb'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "outputs": [],
   "source": [
    "### Save Vacabulary\n",
    "with open(\"C:/Users/putri/DataspellProjects/dsProject/vocab.txt\", \"w\") as file:\n",
    "    file.write(str(vocabulary))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "outputs": [],
   "source": [
    "### load Vacabulary\n",
    "with open(\"C:/Users/putri/DataspellProjects/dsProject/vocab.txt\", \"r\") as file:\n",
    "    data2 = eval(file.readline())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['diatur', 'selamet', 'mama', 'dedik', 'binti', 'gold', 'sari', 'sembilan', 'rachmad', 'dijual', 'core', 'paijo', 'denda', 'umum', 'sebagaimana', 'suryono', 'jean', 'hak', 'bukan', 'danu', 'sebesar', 'damar', 'dosy', 'tosca', 'sepuluh', 'udin', 'aqua', 'andri', 'tetap', 'klip', 'mild', 'ach', 'semula', 'tujuh', 'scoopy', 'menyimpan', 'membeli', 'rifdayanto', 'bersalah', 'serta', 'warna', 'meyakinkan', 'miyanto', 'semua', 'pidana', 'pocket', 'widi', 'zuneehru', 'najih', 'launa', 'besi', 'dunhil', 'merk', 'hamza', 'tutup', 'kariyadi', 'diganti', 'sudarsono', 'la', 'telah', 'aprianto', 'dikurangkan', 'abdul', 'plasstik', 'merek', 'vivo', 'kuswanto', 'plastik', 'jutarupiah', 'grenjeng', 'suprapto', 'sebrat', 'agung', 'zainudin', 'denganberat', 'esse', 'coolmi', 'arvianto', 'dibayar', 'jinjing', 'menetapkan', 'netto', 'achamad', 'surat', 'beli', 'adi', 'menjual', 'lipat', 'diri', 'seberat', 'hijau', 'jahat', 'sutaji', 'suparman', 'sartono', 'cangklong', 'nawariyanto', 'iswahyudi', 'bungusnya', 'gudang', 'andi', 'santoso', 'heri', 'hasil', 'subari', 'sisa', 'melakukan', 'card', 'harnic', 'apabila', 'boy', 'asih', 'sk', 'tipe', 'ungu', 'prekursor', 'rincian', 'redme', 'sedotan', 'puluh', 'yusron', 'pecahan', 'sah', 'wahyudi', 'ulum', 'bendel', 'jual', 'arman', 'sutrisno', 'kosong', 'sejumlah', 'angga', 'rokok', 'kurniawan', 'permen', 'yudha', 'skrop', 'jumlah', 'terdakwa', 'agus', 'menukar', 'menghukum', 'jumain', 'tiok', 'dipergunakan', 'ruf', 'gufron', 'rahmat', 'wisnu', 'poket', 'dari', 'cardnya', 'slamet', 'dibebani', 'soleh', 'di', 'berada', 'hp', 'ribu', 'redmi', 'zein', 'ii', 'penangkapan', 'ke', 'mohammad', 'coklat', 'maulana', 'cap', 'plastiknya', 'negara', 'alternatif', 'subiyat', 'elektrik', 'kantong', 'obeng', 'dibayarkan', 'kesatu', 'wm', 'alias', 'akan', 'segenapnya', 'sesuai', 'hermanto', 'unit', 'barata', 'delapan', 'cholis', 'maliki', 'pemiliknya', 'adem', 'dalam', 'rise', 'kaki', 'juta', 'tua', 'kartini', 'okky', 'uang', 'hisap', 'itu', 'menyerahkan', 'rahman', 'satria', 'bersama', 'lain', 'golongan', 'orang', 'achmad', 'sepeda', 'memulihkan', 'ketentuan', 'kardi', 'saiful', 'timbangan', 'bentuk', 'suprayitno', 'andik', 'kepentingan', 'ta', 'pranggono', 'garam', 'giordano', 'atas', 'para', 'miliar', 'junaidi', 'makhfud', 'gioardano', 'tidak', 'biskuit', 'metalik', 'pipet', 'bin', 'ditimbang', 'kotor', 'moch', 'berat', 'narkotika', 'sendok', 'yamaha', 'infinix', 'dikarenakan', 'ditahan', 'moh', 'bakri', 'paket', 'pipetnya', 'terhadap', 'towan', 'bening', 'selama', 'berisi', 'jaket', 'lipatan', 'surya', 'david', 'pol', 'bekas', 'merah', 'oddi', 'nosim', 'ratus', 'telahdijalani', 'stnk', 'nagarawan', 'xiomi', 'al', 'cardinal', 'vario', 'suzuki', 'antok', 'bersih', 'denganketentuan', 'mukayit', 'tentang', 'pak', 'dilakukan', 'handphone', 'ud', 'koma', 'gambul', 'abu', 'perkara', 'nama', 'fery', 'potongan', 'didalam', 'anggriawan', 'bertuliskan', 'sampurna', 'prangga', 'kompornya', 'b', 'labfor', 'yakni', 'imron', 'melebihi', 'munir', 'penahanan', 'ayat', 'tissue', 'marsuf', 'buah', 'alat', 'nehru', 'sdr', 'putih', 'mochamad', 'potong', 'fasdama', 'nol', 'pendek', 'habis', 'ditahanan', 'beratnya', 'kristal', 'seluruhnya', 'irwan', 'tanpa', 'harus', 'eriansyah', 'sabirin', 'bungkus', 'randa', 'utomo', 'motor', 'terbukti', 'tisue', 'perantara', 'sepenuhnya', 'barang', 'teguh', 'duri', 'bukti', 'lusi', 'setelah', 'robekan', 'agar', 'galesong', 'masa', 'hari', 'heriprayoga', 'prawismo', 'gulungan', 'rupiah', 'kotak', 'milyard', 'mas', 'sim', 'kacanya', 'untuk', 'kecil', 'lusiana', 'ma', 'menjatuhkan', 'shabu', 'lembar', 'nomor', 'mada', 'prasetya', 'sabu', 'setiawan', 'emas', 'eg', 'ghoib', 'kedudukan', 'lea', 'penuntut', 'ada', 'lesmana', 'plastic', 'teh', 'xiaomi', 'tempat', 'seperangkat', 'galaxy', 'yaitu', 'bulan', 'pinggang', 'melawan', 'alvialy', 'kholil', 'dompet', 'purple', 'purwanto', 'rohman', 'terdapat', 'dikurangi', 'beserta', 'zainuri', 'bandel', 'pepen', 'lab', 'supaya', 'permufakatan', 'penjaran', 'sucipto', 'nak', 'dikeluarkan', 'masing', 'simcard', 'sekrop', 'keseluruhan', 'dengan', 'maka', 'novan', 'uu', 'biru', 'menyatakan', 'alm', 'choiril', 'asuz', 'mengusai', 'berupa', 'pertama', 'prasetyo', 'sebba', 'bungkusnya', 'sebagai', 'kertas', 'miftachul', 'billy', 'forensik', 'haier', 'menerima', 'serbuk', 'arif', 'nya', 'habi', 'zulkifli', 'chief', 'sugiyanto', 'chulaifi', 'camel', 'secara', 'atasnya', 'saku', 'sehingga', 'mio', 'mineral', 'satu', 'kombinasi', 'gino', 'oranye', 'batang', 'hermawan', 'milyar', 'ganja', 'pack', 'dua', 'constant', 'puluhsembilan', 'matnazar', 'sau', 'masih', 'suyanto', 'dan', 'susiadi', 'arizona', 'menyediakan', 'khusen', 'mat', 'tunai', 'febri', 'bhaskara', 'honda', 'tahanan', 'ramadany', 'realme', 'agustiansyah', 'kuning', 'sarjono', 'melalui', 'dimusnahkan', 'cahyani', 'kartu', 'joko', 'pemeriksaan', 'pasal', 'gas', 'suandi', 'aminullah', 'bambang', 'tiga', 'segera', 'wahid', 'oleh', 'celup', 'muhammad', 'didalmnya', 'dikembalikan', 'api', 'syarifudin', 'dirampas', 'idris', 'membayar', 'dirusak', 'dwi', 'kaca', 'tersebut', 'mila', 'tissu', 'kresek', 'muda', 'prayoga', 'bong', 'undang', 'choirul', 'rolis', 'minuman', 'stik', 'pujo', 'terpakai', 'sebelas', 'revo', 'hidayat', 'malboro', 'lebih', 'atau', 'hisab', 'naholil', 'berisikan', 'tertancap', 'lamanya', 'nopol', 'karena', 'isolasi', 'diduga', 'gam', 'ini', 'dalamnya', 'belas', 'hukum', 'pakai', 'jika', 'ri', 'chabib', 'seratus', 'jumali', 'aris', 'pula', 'gram', 'lagi', 'memerintahkan', 'oppo', 'dijatuhkan', 'topi', 'tahun', 'memiliki', 'celana', 'kepada', 'membebaskan', 'tanaman', 'dimas', 'satimun', 'yuda', 'artha', 'kurang', 'membebani', 'tk', 'darwis', 'isi', 'penjara', 'botol', 'terbuat', 'saputra', 'silver', 'gama', 'menawarkan', 'tv', 'digital', 'kemudian', 'didalamnya', 'biaya', 'sedangkan', 'hitam', 'air', 'jun', 'rihan', 'ponidi', 'korek', 'dijalani', 'samsung', 'khosim', 'rp', 'ritonga', 'ukuran', 'yunefi', 'wahyu', 'antoko', 'diatas', 'facrudi', 'bahwa', 'sutoyo', 'indonesia', 'siswanto', 'simcardnya', 'republik', 'kedua', 'menjadi', 'budi', 'enam', 'kurungan', 'total', 'yang', 'asus', 'bila', 'dakwaan', 'harkat', 'tindak', 'chozin', 'membebankan', 'susanto', 'dapat', 'lima', 'jenis', 'samadi', 'andhy', 'edi', 'laboratorium', 'darmadi', 'ali', 'mempunyai', 'terdiri', 'martabat', 'sebuah', 'grm', 'ogut', 'empat', 'menguasai', 'eko', 'kriminalistik', 'brutto', 'shihabfudin']\n"
     ]
    }
   ],
   "source": [
    "print(data2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "outputs": [],
   "source": [
    "## Create vector for Query/search keywords\n",
    "def gen_vector_T(tokens):\n",
    "\n",
    "    Q = np.zeros((len(vocabulary)))\n",
    "\n",
    "    x= tfidf.transform(tokens)\n",
    "    for token in tokens[0].split(','):\n",
    "        try:\n",
    "            ind = vocabulary.index(token)\n",
    "            Q[ind]  = x[0, tfidf.vocabulary_[token]]\n",
    "        except:\n",
    "            pass\n",
    "    return Q"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "outputs": [],
   "source": [
    "def cosine_similarity_T(k, query):\n",
    "    #print(\"Cosine Similarity\")\n",
    "    preprocessed_query = preprocessed_query = re.sub(\"\\W+\", \" \", query).strip()\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "    q_df = pd.DataFrame(columns=['q_clean'])\n",
    "    q_df.loc[0,'q_clean'] =tokens\n",
    "    q_df['q_clean'] =wordLemmatizer(q_df.q_clean)\n",
    "    q_df=q_df.replace(to_replace =\"\\[.\", value = '', regex = True)\n",
    "    q_df=q_df.replace(to_replace =\"'\", value = '', regex = True)\n",
    "    q_df=q_df.replace(to_replace =\" \", value = '', regex = True)\n",
    "    q_df=q_df.replace(to_replace ='\\]', value = '', regex = True)\n",
    "    #print(\"\\nQuery:\", query)\n",
    "    #print(\"\")\n",
    "    #print(tokens)\n",
    "\n",
    "    d_cosines = []\n",
    "\n",
    "    query_vector = gen_vector_T(q_df['q_clean'])\n",
    "\n",
    "    for d in tfidf_tran.A:\n",
    "\n",
    "        d_cosines.append(cosine_sim(query_vector, d))\n",
    "\n",
    "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
    "    #print(\"\")\n",
    "    d_cosines.sort()\n",
    "    #print(out)\n",
    "    a = pd.DataFrame()\n",
    "    for i,index in enumerate(out):\n",
    "        a.loc[i,'index'] = str(index)\n",
    "        a.loc[i,'Amar_Putusan'] = df_data['Amar_Putusan'][index]\n",
    "    for j,simScore in enumerate(d_cosines[-k:][::-1]):\n",
    "        a.loc[j,'Score'] = simScore\n",
    "    return a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": "  index                                       Amar_Putusan     Score\n0     8  menyatakan terdakwa suryono bin suparman telah...  0.260302\n1    30  menyatakan terdakwa m. darwis bin mat bakri te...  0.246092\n2    25  menyatakan terdakwa achmad choirul bin subari ...  0.243730\n3    11  menyatakan terdakwa agus budi setiawan alias t...  0.233139\n4    34  menyatakan terdakwa yudha kurniawan arvianto b...  0.231925\n5    27  menyatakan terdakwa fery wisnu saputra alias p...  0.229880\n6    48  menyatakan terdakwa aprianto hermawan alias pa...  0.228033\n7    17  menyatakan terdakwa damar mada bhaskara bin an...  0.227239\n8    16  menyatakan terdakwa randa prayoga bin suprapto...  0.227028\n9    37  menyatakan terdakwa alvialy rifdayanto sebba b...  0.222673",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>Amar_Putusan</th>\n      <th>Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>menyatakan terdakwa suryono bin suparman telah...</td>\n      <td>0.260302</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30</td>\n      <td>menyatakan terdakwa m. darwis bin mat bakri te...</td>\n      <td>0.246092</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25</td>\n      <td>menyatakan terdakwa achmad choirul bin subari ...</td>\n      <td>0.243730</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>menyatakan terdakwa agus budi setiawan alias t...</td>\n      <td>0.233139</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>34</td>\n      <td>menyatakan terdakwa yudha kurniawan arvianto b...</td>\n      <td>0.231925</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>27</td>\n      <td>menyatakan terdakwa fery wisnu saputra alias p...</td>\n      <td>0.229880</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>48</td>\n      <td>menyatakan terdakwa aprianto hermawan alias pa...</td>\n      <td>0.228033</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>17</td>\n      <td>menyatakan terdakwa damar mada bhaskara bin an...</td>\n      <td>0.227239</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>16</td>\n      <td>menyatakan terdakwa randa prayoga bin suprapto...</td>\n      <td>0.227028</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>37</td>\n      <td>menyatakan terdakwa alvialy rifdayanto sebba b...</td>\n      <td>0.222673</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time cosine_similarity_T(10,'terdakwa')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
